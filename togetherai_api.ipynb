{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29aa5913-a050-4165-bf8d-2c43a0fe6e5d",
   "metadata": {},
   "source": [
    "## Together AI API \n",
    "- [python api docs](https://docs.together.ai/docs/inference-python)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ce3a707-85cf-46f4-8526-217243d7c797",
   "metadata": {},
   "outputs": [],
   "source": [
    "import together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "099b2490-2f8b-40ba-9a83-2d20431de7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "together.api_key = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2fa6df-1fbb-43fb-9b00-ceeeaddf07c5",
   "metadata": {},
   "source": [
    "## Select Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5d1866e-18ba-4d71-ae27-8cad8fceb6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117 models available\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Austism/chronos-hermes-13b',\n",
       " 'DiscoResearch/DiscoLM-mixtral-8x7b-v2',\n",
       " 'EleutherAI/llemma_7b',\n",
       " 'Gryphe/MythoMax-L2-13b',\n",
       " 'Meta-Llama/Llama-Guard-7b',\n",
       " 'Nexusflow/NexusRaven-V2-13B',\n",
       " 'NousResearch/Nous-Capybara-7B-V1p9',\n",
       " 'NousResearch/Nous-Hermes-Llama2-13b',\n",
       " 'NousResearch/Nous-Hermes-Llama2-70b',\n",
       " 'NousResearch/Nous-Hermes-llama-2-7b']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see available models\n",
    "model_list = together.Models.list()\n",
    "\n",
    "print(f\"{len(model_list)} models available\")\n",
    "\n",
    "# print the first 10 models on the menu\n",
    "model_names = [model_dict['name'] for model_dict in model_list]\n",
    "model_names[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebd213b-ceaf-46c9-a2ce-322cd8792133",
   "metadata": {},
   "source": [
    "## Pull up Mistral Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5566f49b-c3f1-413d-b5cc-e0afd6f90533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Open-Orca/Mistral-7B-OpenOrca',\n",
       " 'mistralai/Mistral-7B-Instruct-v0.1',\n",
       " 'mistralai/Mistral-7B-v0.1',\n",
       " 'mistralai/Mixtral-8x7B-Instruct-v0.1',\n",
       " 'teknium/OpenHermes-2-Mistral-7B',\n",
       " 'teknium/OpenHermes-2p5-Mistral-7B',\n",
       " 'mistralai/Mixtral-8x7B-v0.1']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in model_names if 'mistral' in x.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bc9964c-be49-48f9-8026-45970b4dcb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_use='mistralai/Mixtral-8x7B-Instruct-v0.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ab5e1f3-e845-4bb7-8644-03002a670a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best Christmas song of the 21st Century is subjective and depends on personal preference. However, a popular choice among many is \"All I Want for Christmas Is You\" by Mariah Carey, which was released in 1994 but gained significant popularity in the 21st century. Other notable songs include \"Underneath the Arches\" by Josh Groban and \"Where Are You Christmas?\" by Faith Hill.\n"
     ]
    }
   ],
   "source": [
    "output = together.Complete.create(\n",
    "  prompt = \"<human>: What is the best christmas song of the 21st Century?\\n<bot>:\", \n",
    "  model = model_to_use, \n",
    "  max_tokens = 256,\n",
    "  temperature = 0.8,\n",
    "  top_k = 60,\n",
    "  top_p = 0.6,\n",
    "  repetition_penalty = 1.1,\n",
    "  stop = ['<human>', '\\n\\n']\n",
    ")\n",
    "\n",
    "# print generated text\n",
    "print(output['output']['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59932a29-4c62-4ffc-817d-b34c2f2ee2e2",
   "metadata": {},
   "source": [
    "## Try Image Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa41211f-269a-448e-a91c-07e8354d9901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "# generate image \n",
    "response = together.Image.create(prompt=\"Jolly snowman\")\n",
    "\n",
    "# save the first image\n",
    "image = response[\"output\"][\"choices\"][0]\n",
    "with open(\"snowman.png\", \"wb\") as f:\n",
    "    f.write(base64.b64decode(image[\"image_base64\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e178618-efd5-45f2-a42a-90ded72a1fde",
   "metadata": {},
   "source": [
    "## Didn't really work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd95ad2-2f40-4f17-8a48-dfdbe846d34f",
   "metadata": {},
   "source": [
    "## Try for a RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f65cad-6c22-4613-8633-7b4c6096088b",
   "metadata": {},
   "source": [
    "## Function to get answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a56c5152-748b-4551-9221-1dc3ddd94eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mistralai/Mixtral-8x7B-Instruct-v0.1'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_to_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d92c76d2-d440-4c5e-993c-80176cadb1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_llm(question,\n",
    "            system_prompt=system_prompt,\n",
    "            max_tokens=2048, \n",
    "            model=model_to_use):\n",
    "\n",
    "    # this format appears to be necessary\n",
    "    prompt = f\"<human>: {question}\\n<bot>:\"\n",
    "    response =  together.Complete.create(\n",
    "                  prompt = prompt, \n",
    "                  model = model, \n",
    "                  max_tokens = max_tokens,\n",
    "                  temperature = 0.8,\n",
    "                  top_k = 60,\n",
    "                  top_p = 0.6,\n",
    "                  repetition_penalty = 1.1,\n",
    "                  stop = ['<human>', '\\n\\n']\n",
    "                )\n",
    "\n",
    "    return response['output']['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e7a7f6-6f5a-456d-9d5e-f57551249811",
   "metadata": {},
   "source": [
    "## Test Message Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "11291b15-e647-4441-82f1-dfbd3a45f139",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'what is narcissism?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb97b7d-dc13-48f7-8a38-7ee714154221",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = ask_llm(question,model='NousResearch/Nous-Hermes-Llama2-70b', max_tokens=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cc54d2-2af0-48a4-ad52-4062f43cdf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9a6af8-11b7-47d0-a1c5-81f0903e91dd",
   "metadata": {},
   "source": [
    "## Test Function over set of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "93eebdb6-d1d9-4fd7-a781-594f80d72371",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens = 2048\n",
    "model='mistral-7b-instruct'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fc748325-e3cd-4b06-ba71-9c4eff1d8915",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    'mistralai/Mixtral-8x7B-Instruct-v0.1',\n",
    "    'teknium/OpenHermes-2p5-Mistral-7B',\n",
    "    'NousResearch/Nous-Hermes-llama-2-7b',\n",
    "    'togethercomputer/llama-2-70b',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fae442-401b-4e88-b62c-041a5689e8dd",
   "metadata": {},
   "source": [
    "## Compare Model Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aede3a6c-b51d-4250-b016-50dde48a64c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'who in your estimation are the most influential computer scientists of the 21st century?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866b6b53-3b8f-4ac8-86dc-b4bda06a994f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_answers = {}\n",
    "\n",
    "for model in models:\n",
    "    answer = ask_llm(question=question, model=model)\n",
    "    model_answers[model] = answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7c5318-5787-42f7-881c-79dad25e07b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_answers.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "266a19f7-67e6-4043-b8b4-40ae05e49db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Determining the most influential computer scientists of the 21st century can be subjective and depends on the criteria used. However, here are a few who have made significant contributions:'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_answers['']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36fd2e4-45e5-4e73-aa20-704a51fc17d4",
   "metadata": {},
   "source": [
    "## UPDATE FROM HERE\n",
    "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!1111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c204b9d9-1e3e-44a4-bf49-34c41874d6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a39e63b-b8e1-4459-9597-02907781ff65",
   "metadata": {},
   "source": [
    "# Use as a RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d541c23d-17a8-43de-aa3f-67cb69e7b627",
   "metadata": {},
   "source": [
    "## Embed Articles from The Last Psychiatrist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "80f8513d-19c0-4f5f-822e-cc6562483e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".gitattributes: 100%|██████████████████████████████████████████████████████████████████████████████| 1.18k/1.18k [00:00<00:00, 191kB/s]\n",
      "1_Pooling/config.json: 100%|██████████████████████████████████████████████████████████████████████████| 190/190 [00:00<00:00, 24.6kB/s]\n",
      "README.md: 100%|██████████████████████████████████████████████████████████████████████████████████| 10.6k/10.6k [00:00<00:00, 6.21MB/s]\n",
      "config.json: 100%|█████████████████████████████████████████████████████████████████████████████████████| 612/612 [00:00<00:00, 348kB/s]\n",
      "config_sentence_transformers.json: 100%|██████████████████████████████████████████████████████████████| 116/116 [00:00<00:00, 47.6kB/s]\n",
      "data_config.json: 100%|███████████████████████████████████████████████████████████████████████████| 39.3k/39.3k [00:00<00:00, 16.0MB/s]\n",
      "pytorch_model.bin: 100%|██████████████████████████████████████████████████████████████████████████| 90.9M/90.9M [00:02<00:00, 41.0MB/s]\n",
      "sentence_bert_config.json: 100%|████████████████████████████████████████████████████████████████████| 53.0/53.0 [00:00<00:00, 7.63kB/s]\n",
      "special_tokens_map.json: 100%|████████████████████████████████████████████████████████████████████████| 112/112 [00:00<00:00, 74.1kB/s]\n",
      "tokenizer.json: 100%|███████████████████████████████████████████████████████████████████████████████| 466k/466k [00:00<00:00, 6.73MB/s]\n",
      "tokenizer_config.json: 100%|███████████████████████████████████████████████████████████████████████████| 350/350 [00:00<00:00, 232kB/s]\n",
      "train_script.py: 100%|████████████████████████████████████████████████████████████████████████████| 13.2k/13.2k [00:00<00:00, 8.24MB/s]\n",
      "vocab.txt: 100%|████████████████████████████████████████████████████████████████████████████████████| 232k/232k [00:00<00:00, 58.8MB/s]\n",
      "modules.json: 100%|████████████████████████████████████████████████████████████████████████████████████| 349/349 [00:00<00:00, 188kB/s]\n"
     ]
    }
   ],
   "source": [
    "# use tiny model for embeddings\n",
    "model_id = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embeddings = HuggingFaceEmbeddings(model_name=model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "38b22833-3a61-46e3-a648-2a8ccd7f1b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load text data from a file using TextLoader\n",
    "loader = TextLoader('data/who_can_know_how_much_randi_zu.txt')\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "76b11cc3-0c51-4702-99f2-3c144f532b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# format it for processing by embedding model\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "text_chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "22680c56-34da-43c8-a1ae-b6a3941af6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore_of_docs = FAISS.from_documents(text_chunks, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21eec74-d833-4d80-b766-fdd2a1c02f6f",
   "metadata": {},
   "source": [
    "## Function to prep docs for encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "18506a7d-35ae-4b58-9258-5edf37e98762",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text_files_for_encoding(file_names, dir):\n",
    "    documents = []\n",
    "    for text_file in file_names:\n",
    "        loader = TextLoader(str(directory) + '/' + text_file)\n",
    "        documents.extend(loader.load())\n",
    "    \n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "    chunked_documents = text_splitter.split_documents(documents)\n",
    "\n",
    "    return chunked_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64516fc9-00bf-45d4-9f74-cbc30936110c",
   "metadata": {},
   "source": [
    "## Encoding a bunch of documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "40944da1-3adf-4129-9892-b08fd1d33307",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = Path('/home/nick/Documents/repos/llm_playground/data')\n",
    "\n",
    "file_names = [file.name for file in directory.glob('*.txt')]\n",
    "\n",
    "chunked_documents = load_text_files_for_encoding(file_names, directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ddafef5c-7f5c-4425-a5f9-f4d9aad8f3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore_of_docs = FAISS.from_documents(chunked_documents, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc63426-2f82-4ce5-bd28-d4db98b83ae9",
   "metadata": {},
   "source": [
    "## Test the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "83982074-c824-49ff-96e1-c1d2884346cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "related_text = vectorstore_of_docs.similarity_search('narcissism',top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "273d15a3-dbd8-487e-afec-bacb3dbd1f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"who like her-- the people she has to settle for-- are... not great.Genetics took care of her body but the upbringing affected her vision: the childhood of never good enough filters her present reality, obscures it, she can't see what is plain to everyone else, e.g. she's beautiful. So the process is to uncover the reasons why her view of reality is distorted and help her realign with reality. Use insight to strengthen her damaged ego, or, if you want a ten step approach, block automatic thoughts. In short, to understand that she is good, that men do find her attractive, not just the brazen ones, not just jerks.IV.If you think of narcissism as grandiosity you miss the nuances, e.g. in her case the problem is narcissism without any grandiosity: she is so consumed with her identity (as not pretty) that she is not able to read, to empathize with, other people's feelings. She doesn't care to try because it conflicts with how she sees herself. Ergo: Giorgio Armani was just being nice.I\", metadata={'source': '/home/nick/Documents/repos/llm_playground/data/just_because_you_see_it_doesnt.txt'}),\n",
       " Document(page_content='interesting thing about addictions-- include gambling and sex and internet and \"dangerous behaviors\" and whatever else you want-- is that they all share something in common.\\xa0 Allegedly this thing is dopaminergic pathways to the striatum and etc, but saying that gets you nothing.\\xa0 It\\'s astounding that the layperson chooses to think in these terms which though they are true are utterly meaningless, utterly unactionable, until you remember, oh, of course, in narcissism believing something is preferable to doing something because the former is about you and the latter is about everyone else.Slightly off topic but here\\'s an important example: say you yell every day at an/your eight year old girl for sloppy homework, admittedly a terrible thing to do but not uncommon, and eventually she thinks, \"I\\'m terrible at everything\" and gives up, so the standard interpretation of this is that she has lost self-confidence, she\\'s been demoralized, and case by case you may be right, but there\\'s another', metadata={'source': '/home/nick/Documents/repos/llm_playground/data/amy_schumer_offers_you_a_look.txt'}),\n",
       " Document(page_content=\"so far?\\xa0 Do you think you've understood?You heard the story, you heard the words, but your mind unheard it and replaced it with something else.\\xa0 Even after I tell you this, you'll have trouble remembering it. You think Narcissus was so in love with himself that he couldn't love anyone else.\\xa0 But that's not what happened, the story clearly tells it in the reverse: he never loved anyone and then he fell in love with himself.\\xa0 Do you see?\\xa0 Because he never loved anyone, he fell in love with himself.\\xa0\\xa0 That was Narcissus's punishment.\\xa0 You thought Narcissus rejected all those people because he was in love with himself, but he rejected them all before he loved himself.\\xa0 Loved himself?\\xa0 Do you think Narcissus rejected them because he thought he was better than them?\\xa0 Or better looking?\\xa0 How would he have known he was so beautiful?\\xa0 He didn't even recognize his own reflection!\\xa0 He rejected all those people because they loved him. IV.You thought nemesis meant enemy, you thought it meant the\", metadata={'source': '/home/nick/Documents/repos/llm_playground/data/the_story_of_narcissus.txt'}),\n",
       " Document(page_content='the woods, ensuring that he\\'d someday have cause to do it.\\xa0\\xa0\\xa0 And so when Narcissus\\'s parents heard the requirements for their child\\'s long life... they would have done everything possible to ensure that he didn\\'t know himself.No one knows what Liriope and Cephisus did, but whatever they did, it worked: he didn\\'t even recognize his own reflection.\\xa0 That\\'s a man who doesn\\'t know himself. That\\'s a man who never had to look at himself from the outside.How do you make a child know himself?\\xa0 You surround him with mirrors. \"This is what everyone else sees when you do what you do.\\xa0 This is who everyone thinks you are.\"You cause him to be tested: this is the kind of person you are, you are good at this but not that. This other person is better than you at this, but not better than you at that.\\xa0 These are the limits by which you are defined.\\xa0\\xa0 Narcissus was never allowed to meet real danger, glory, struggle, honor, success, failure; only artificial versions manipulated by his parents.\\xa0\\xa0 He was', metadata={'source': '/home/nick/Documents/repos/llm_playground/data/the_story_of_narcissus.txt'})]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "related_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f184257-4a0d-4944-804c-73dcf4b902ca",
   "metadata": {},
   "source": [
    "## Ask Question with Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "8810d42e-2eea-445f-af53-d1190a9f2b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_llm2(question,\n",
    "            max_tokens=2048, \n",
    "            model,\n",
    "           context=False,\n",
    "           top_k=5,\n",
    "           vectorstore=False):\n",
    "    'Ask the perplexity api a question, with or without context, using whichever model you prefer'\n",
    "\n",
    "    if context == True:\n",
    "        # find relevant text and add it to question\n",
    "        related_text = vectorstore.similarity_search(question,top_k)\n",
    "        context = ' / '.join([related_text[i].page_content for i in range(top_k)])\n",
    "        files_used = ','.join(set([related_text[i].metadata['source'] for i in range(top_k)]))\n",
    "        context_string = f'{context} || from the files {files_used}'\n",
    "        # update question string\n",
    "        question =  f'''Use the following pieces of context to answer the question at the end. \n",
    "            Try to make the response brief and only answer the portion after Question:\n",
    "            Do not refer to the text from this prompt outside of the context.\n",
    "            Structure your answers as well composed english sentences and do not include '\\n'\n",
    "            \n",
    "            {context_string}\n",
    "            \n",
    "            Question: {question}\n",
    "            Answer: '''\n",
    "    \n",
    "    # this format appears to be necessary\n",
    "    prompt = f\"<human>: {question}\\n<bot>:\"\n",
    "    response =  together.Complete.create(\n",
    "                  prompt = prompt, \n",
    "                  model = model, \n",
    "                  max_tokens = max_tokens,\n",
    "                  temperature = 0.8,\n",
    "                  top_k = 60,\n",
    "                  top_p = 0.6,\n",
    "                  repetition_penalty = 1.1,\n",
    "                  stop = ['<human>', '\\n\\n']\n",
    "                )\n",
    "\n",
    "    return response['output']['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "b28df2c6-44b0-4d26-a5de-1ca502f976db",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query = 'Why is Randi Zuckerberg well known?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "f66c4a12-396b-465d-b60d-94e978d5f318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Randi Zuckerberg is well known because she is the sister of Mark Zuckerberg, the founder and CEO of Facebook. She is also an entrepreneur and a philanthropist in her own right, and has been involved in several successful ventures and initiatives. Randi has been featured in numerous media outlets and has been recognized for her work and achievements in the tech industry.'"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_ppl(test_query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
